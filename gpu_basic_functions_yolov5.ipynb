{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e4511c05-0d32-4419-ac87-84218e389d7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install watermark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "adc1c48b-d084-456f-9681-6c31f3809058",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    for i in range(torch.cuda.device_count()):\n",
    "        torch.cuda.get_device_name(i)\n",
    "else:\n",
    "    print(f\"Cuda is available: {torch.cuda.is_available()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "29bc2fbc-1446-47c2-b6e9-7081303daa59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PRO TIP 💡 Replace 'model=yolov5s.pt' with new 'model=yolov5su.pt'.\n",
      "YOLOv5 'u' models are trained with https://github.com/ultralytics/ultralytics and feature improved performance vs standard YOLOv5 models trained with https://github.com/ultralytics/yolov5.\n",
      "\n",
      "New https://pypi.org/project/ultralytics/8.1.33 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.1.32 🚀 Python-3.12.2 torch-2.2.1 CUDA:0 (NVIDIA GeForce RTX 3050 Ti Laptop GPU, 4096MiB)\n",
      "\u001b[34m\u001b[1mengine\\trainer: \u001b[0mtask=detect, mode=train, model=yolov5s.pt, data=coco128.yaml, epochs=15, time=None, patience=100, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=train4, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs\\detect\\train4\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      3520  ultralytics.nn.modules.conv.Conv             [3, 32, 6, 2, 2]              \n",
      "  1                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  2                  -1  1     18816  ultralytics.nn.modules.block.C3              [64, 64, 1]                   \n",
      "  3                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  4                  -1  2    115712  ultralytics.nn.modules.block.C3              [128, 128, 2]                 \n",
      "  5                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  6                  -1  3    625152  ultralytics.nn.modules.block.C3              [256, 256, 3]                 \n",
      "  7                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \n",
      "  8                  -1  1   1182720  ultralytics.nn.modules.block.C3              [512, 512, 1]                 \n",
      "  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n",
      " 10                  -1  1    131584  ultralytics.nn.modules.conv.Conv             [512, 256, 1, 1]              \n",
      " 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 13                  -1  1    361984  ultralytics.nn.modules.block.C3              [512, 256, 1, False]          \n",
      " 14                  -1  1     33024  ultralytics.nn.modules.conv.Conv             [256, 128, 1, 1]              \n",
      " 15                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 16             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 17                  -1  1     90880  ultralytics.nn.modules.block.C3              [256, 128, 1, False]          \n",
      " 18                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 19            [-1, 14]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 20                  -1  1    296448  ultralytics.nn.modules.block.C3              [256, 256, 1, False]          \n",
      " 21                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
      " 22            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 23                  -1  1   1182720  ultralytics.nn.modules.block.C3              [512, 512, 1, False]          \n",
      " 24        [17, 20, 23]  1   2147008  ultralytics.nn.modules.head.Detect           [80, [128, 256, 512]]         \n",
      "YOLOv5s summary: 262 layers, 9153152 parameters, 9153136 gradients\n",
      "\n",
      "Transferred 427/427 items from pretrained weights\n",
      "Freezing layer 'model.24.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning C:\\01_projects\\YOLOv5_wSciAugment\\datasets\\coco128\\labels\\train2017.cache... 126 images, 2 backgrounds,\u001b[0m\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\01_projects\\YOLOv5_wSciAugment\\datasets\\coco128\\labels\\train2017.cache... 126 images, 2 backgrounds, 0\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs\\detect\\train4\\labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.000119, momentum=0.9) with parameter groups 69 weight(decay=0.0), 76 weight(decay=0.0005), 75 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 8 dataloader workers\n",
      "Logging results to \u001b[1mruns\\detect\\train4\u001b[0m\n",
      "Starting training for 15 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       1/15      4.28G      1.151      1.325      1.236        178        640: 100%|██████████| 8/8 [00:40<00:00,  5.11\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:12<0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        128        929      0.752      0.652      0.746      0.565\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       2/15      4.31G       1.14      1.197      1.209        231        640: 100%|██████████| 8/8 [00:08<00:00,  1.00\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:07<0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        128        929      0.725      0.698      0.759      0.571\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       3/15      4.35G      1.108       1.14      1.156        178        640: 100%|██████████| 8/8 [00:06<00:00,  1.29\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:05<0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        128        929      0.726      0.719       0.76      0.575\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       4/15      4.15G       1.15      1.173      1.196        323        640: 100%|██████████| 8/8 [00:04<00:00,  1.76\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:06<0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        128        929      0.756        0.7      0.767      0.582\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       5/15      4.36G      1.076      1.035      1.168        199        640: 100%|██████████| 8/8 [00:05<00:00,  1.44\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:07<0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        128        929      0.804      0.697      0.777      0.596\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closing dataloader mosaic\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       6/15      4.33G      1.042      1.019      1.103        113        640: 100%|██████████| 8/8 [00:08<00:00,  1.02\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:08<0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        128        929      0.779      0.751      0.793       0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       7/15      4.33G       1.02     0.9499      1.103         73        640: 100%|██████████| 8/8 [00:04<00:00,  1.73\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:06<0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        128        929      0.777      0.748      0.801      0.621\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       8/15      4.28G     0.9981     0.9145      1.071        143        640: 100%|██████████| 8/8 [00:04<00:00,  1.80\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:05<0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        128        929      0.805      0.737      0.807      0.632\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       9/15      4.28G     0.9718     0.8303      1.086        112        640: 100%|██████████| 8/8 [00:04<00:00,  1.92\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:04<0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        128        929      0.816      0.741      0.805      0.635\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      10/15      4.34G      1.002      0.862      1.087        162        640: 100%|██████████| 8/8 [00:04<00:00,  1.65\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:04<0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        128        929      0.841      0.732      0.814      0.648\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      11/15      4.21G     0.9469     0.8267      1.066         89        640: 100%|██████████| 8/8 [00:04<00:00,  1.91\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:03<0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        128        929      0.859       0.73      0.819      0.652\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      12/15      4.27G     0.9793     0.8066      1.071        135        640: 100%|██████████| 8/8 [00:05<00:00,  1.52\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:05<0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        128        929      0.869      0.734       0.82      0.657\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      13/15      4.34G     0.9557     0.7929      1.052         79        640: 100%|██████████| 8/8 [00:04<00:00,  1.64\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:04<0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        128        929      0.867      0.738      0.822      0.659\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      14/15      4.35G     0.9378     0.7799       1.05        126        640: 100%|██████████| 8/8 [00:05<00:00,  1.59\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:05<0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        128        929      0.866      0.737      0.823      0.661\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      15/15      4.33G     0.9434     0.8103      1.061        107        640: 100%|██████████| 8/8 [00:05<00:00,  1.55\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:04<0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        128        929      0.866      0.738      0.823      0.662\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "15 epochs completed in 0.089 hours.\n",
      "Optimizer stripped from runs\\detect\\train4\\weights\\last.pt, 18.6MB\n",
      "Optimizer stripped from runs\\detect\\train4\\weights\\best.pt, 18.6MB\n",
      "\n",
      "Validating runs\\detect\\train4\\weights\\best.pt...\n",
      "Ultralytics YOLOv8.1.32 🚀 Python-3.12.2 torch-2.2.1 CUDA:0 (NVIDIA GeForce RTX 3050 Ti Laptop GPU, 4096MiB)\n",
      "YOLOv5s summary (fused): 193 layers, 9142496 parameters, 0 gradients\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:03<0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        128        929      0.866      0.738      0.823      0.663\n",
      "                person        128        254      0.941      0.696      0.856       0.64\n",
      "               bicycle        128          6          1      0.369      0.809      0.465\n",
      "                   car        128         46      0.833      0.326      0.556      0.291\n",
      "            motorcycle        128          5      0.877          1      0.995      0.877\n",
      "              airplane        128          6      0.944          1      0.995      0.928\n",
      "                   bus        128          7      0.781          1      0.995       0.84\n",
      "                 train        128          3      0.858          1      0.995      0.765\n",
      "                 truck        128         12      0.925        0.5      0.593      0.414\n",
      "                  boat        128          6      0.685       0.37      0.699      0.545\n",
      "         traffic light        128         14       0.97      0.429      0.431       0.27\n",
      "             stop sign        128          2      0.935          1      0.995      0.847\n",
      "                 bench        128          9      0.998      0.778      0.922        0.7\n",
      "                  bird        128         16          1      0.987      0.995      0.727\n",
      "                   cat        128          4      0.901          1      0.995      0.946\n",
      "                   dog        128          9          1       0.95      0.995      0.829\n",
      "                 horse        128          2      0.824          1      0.995        0.8\n",
      "              elephant        128         17      0.902      0.941      0.959      0.806\n",
      "                  bear        128          1      0.721          1      0.995      0.995\n",
      "                 zebra        128          4      0.898          1      0.995      0.975\n",
      "               giraffe        128          9          1       0.88      0.995      0.854\n",
      "              backpack        128          6          1      0.571      0.714      0.571\n",
      "              umbrella        128         18      0.811      0.889      0.949       0.71\n",
      "               handbag        128         19      0.871      0.421      0.492      0.377\n",
      "                   tie        128          7      0.851      0.821      0.818       0.62\n",
      "              suitcase        128          4      0.931          1      0.995      0.734\n",
      "               frisbee        128          5      0.873        0.8      0.806      0.727\n",
      "                  skis        128          1      0.932          1      0.995      0.597\n",
      "             snowboard        128          7      0.722      0.857      0.897      0.717\n",
      "           sports ball        128          6          1      0.577      0.676      0.379\n",
      "                  kite        128         10      0.821      0.462      0.605      0.256\n",
      "          baseball bat        128          4      0.953        0.5      0.547      0.433\n",
      "        baseball glove        128          7      0.899      0.429      0.433      0.252\n",
      "            skateboard        128          5      0.643        0.8      0.805      0.611\n",
      "         tennis racket        128          7      0.979      0.714      0.719      0.566\n",
      "                bottle        128         18       0.84      0.278       0.77      0.535\n",
      "            wine glass        128         16      0.774      0.625      0.817      0.583\n",
      "                   cup        128         36      0.859      0.677      0.832      0.608\n",
      "                  fork        128          6      0.596      0.167      0.454      0.348\n",
      "                 knife        128         16          1      0.514      0.836      0.587\n",
      "                 spoon        128         22      0.947      0.727      0.753      0.509\n",
      "                  bowl        128         28       0.95      0.786      0.853      0.741\n",
      "                banana        128          1          1          0      0.995      0.895\n",
      "              sandwich        128          2      0.772          1      0.995      0.995\n",
      "                orange        128          4      0.781          1      0.995      0.734\n",
      "              broccoli        128         11      0.633      0.364       0.48      0.365\n",
      "                carrot        128         24      0.806      0.875      0.874      0.656\n",
      "               hot dog        128          2      0.802          1      0.995      0.995\n",
      "                 pizza        128          5       0.93          1      0.995       0.91\n",
      "                 donut        128         14      0.687          1      0.962      0.908\n",
      "                  cake        128          4      0.894          1      0.995      0.904\n",
      "                 chair        128         35      0.726      0.605      0.723      0.471\n",
      "                 couch        128          6          1      0.975      0.995      0.814\n",
      "          potted plant        128         14       0.84       0.75      0.901      0.708\n",
      "                   bed        128          3      0.854          1      0.995       0.93\n",
      "          dining table        128         13      0.814      0.674       0.77      0.653\n",
      "                toilet        128          2      0.836          1      0.995      0.946\n",
      "                    tv        128          2      0.598          1      0.995      0.848\n",
      "                laptop        128          3      0.801          1      0.995      0.895\n",
      "                 mouse        128          2          1          0      0.108     0.0748\n",
      "                remote        128          8      0.983      0.625      0.639      0.532\n",
      "            cell phone        128          8      0.806        0.5      0.607      0.458\n",
      "             microwave        128          3      0.872          1      0.995      0.864\n",
      "                  oven        128          5      0.519      0.439      0.522      0.454\n",
      "                  sink        128          6      0.862      0.667      0.817       0.55\n",
      "          refrigerator        128          5          1      0.967      0.995      0.849\n",
      "                  book        128         29      0.837      0.356      0.673      0.358\n",
      "                 clock        128          9      0.921      0.889      0.932      0.795\n",
      "                  vase        128          2      0.867          1      0.995      0.945\n",
      "              scissors        128          1          1          0          0          0\n",
      "            teddy bear        128         21      0.833      0.905       0.97      0.709\n",
      "            toothbrush        128          5          1      0.964      0.995      0.857\n",
      "Speed: 0.3ms preprocess, 7.1ms inference, 0.0ms loss, 3.2ms postprocess per image\n",
      "Results saved to \u001b[1mruns\\detect\\train4\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "# Create a new YOLO model from scratch\n",
    "# model = YOLO('yolov8n.yaml')\n",
    "\n",
    "# Load a pretrained YOLO model (recommended for training)\n",
    "model = YOLO(\"yolov5s.pt\")\n",
    "\n",
    "# Train the model using the 'coco128.yaml' dataset for 3 epochs\n",
    "results = model.train(data=\"coco128.yaml\", epochs=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "efec8e05-a405-4e97-af79-b189fa3e7235",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.1.32 🚀 Python-3.12.2 torch-2.2.1 CUDA:0 (NVIDIA GeForce RTX 3050 Ti Laptop GPU, 4096MiB)\n",
      "YOLOv5s summary (fused): 193 layers, 9142496 parameters, 0 gradients\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\01_projects\\YOLOv5_wSciAugment\\datasets\\coco128\\labels\\train2017.cache... 126 images, 2 backgrounds, 0\u001b[0m\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:19<0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        128        929      0.874      0.741      0.824      0.658\n",
      "                person        128        254      0.932      0.703      0.854      0.641\n",
      "               bicycle        128          6          1      0.368      0.809       0.46\n",
      "                   car        128         46      0.781      0.304      0.524      0.286\n",
      "            motorcycle        128          5      0.877          1      0.995      0.877\n",
      "              airplane        128          6      0.943          1      0.995      0.928\n",
      "                   bus        128          7      0.781          1      0.995       0.84\n",
      "                 train        128          3      0.857          1      0.995      0.753\n",
      "                 truck        128         12          1      0.494      0.615      0.438\n",
      "                  boat        128          6      0.699      0.398      0.753      0.557\n",
      "         traffic light        128         14      0.987      0.429      0.447      0.271\n",
      "             stop sign        128          2      0.938          1      0.995      0.847\n",
      "                 bench        128          9      0.996      0.778      0.925      0.702\n",
      "                  bird        128         16          1      0.988      0.995      0.727\n",
      "                   cat        128          4      0.901          1      0.995      0.946\n",
      "                   dog        128          9          1       0.95      0.995      0.829\n",
      "                 horse        128          2      0.823          1      0.995        0.8\n",
      "              elephant        128         17      0.902      0.941      0.959      0.806\n",
      "                  bear        128          1      0.721          1      0.995      0.995\n",
      "                 zebra        128          4      0.898          1      0.995      0.975\n",
      "               giraffe        128          9          1      0.879      0.995      0.868\n",
      "              backpack        128          6          1      0.571      0.717      0.564\n",
      "              umbrella        128         18      0.813      0.889      0.949      0.719\n",
      "               handbag        128         19      0.868      0.421      0.494      0.368\n",
      "                   tie        128          7      0.851       0.82      0.818       0.62\n",
      "              suitcase        128          4       0.93          1      0.995      0.734\n",
      "               frisbee        128          5      0.873        0.8      0.806      0.727\n",
      "                  skis        128          1      0.931          1      0.995      0.597\n",
      "             snowboard        128          7      0.741      0.821      0.878      0.687\n",
      "           sports ball        128          6          1      0.578      0.675      0.392\n",
      "                  kite        128         10      0.824      0.472      0.605      0.239\n",
      "          baseball bat        128          4      0.951        0.5       0.56      0.438\n",
      "        baseball glove        128          7      0.855      0.429      0.434       0.26\n",
      "            skateboard        128          5      0.693        0.8      0.795      0.641\n",
      "         tennis racket        128          7      0.976      0.714      0.719       0.59\n",
      "                bottle        128         18      0.841      0.296      0.765      0.516\n",
      "            wine glass        128         16      0.774      0.625      0.822      0.596\n",
      "                   cup        128         36      0.888      0.661      0.817      0.603\n",
      "                  fork        128          6          1      0.309      0.529      0.412\n",
      "                 knife        128         16          1      0.485      0.798      0.561\n",
      "                 spoon        128         22      0.847      0.727      0.753      0.519\n",
      "                  bowl        128         28      0.939      0.786      0.855      0.737\n",
      "                banana        128          1          1          0      0.995      0.796\n",
      "              sandwich        128          2      0.794          1      0.995      0.995\n",
      "                orange        128          4      0.783          1      0.995      0.734\n",
      "              broccoli        128         11      0.667      0.455      0.485      0.376\n",
      "                carrot        128         24      0.807      0.875      0.872      0.649\n",
      "               hot dog        128          2      0.807          1      0.995      0.995\n",
      "                 pizza        128          5       0.92          1      0.995      0.895\n",
      "                 donut        128         14      0.687          1      0.962        0.9\n",
      "                  cake        128          4      0.894          1      0.995      0.904\n",
      "                 chair        128         35      0.723        0.6      0.741      0.455\n",
      "                 couch        128          6          1      0.975      0.995      0.814\n",
      "          potted plant        128         14       0.84      0.752      0.901      0.708\n",
      "                   bed        128          3      0.864          1      0.995      0.865\n",
      "          dining table        128         13      0.902      0.707      0.796      0.649\n",
      "                toilet        128          2      0.837          1      0.995      0.946\n",
      "                    tv        128          2      0.598          1      0.995      0.848\n",
      "                laptop        128          3      0.805          1      0.995      0.895\n",
      "                 mouse        128          2          1          0      0.112     0.0768\n",
      "                remote        128          8      0.983      0.625      0.641      0.551\n",
      "            cell phone        128          8      0.805        0.5      0.607      0.437\n",
      "             microwave        128          3      0.876          1      0.995      0.864\n",
      "                  oven        128          5      0.588        0.4      0.522      0.454\n",
      "                  sink        128          6      0.959      0.667      0.788      0.502\n",
      "          refrigerator        128          5          1      0.982      0.995      0.849\n",
      "                  book        128         29      0.768      0.343      0.647      0.351\n",
      "                 clock        128          9      0.921      0.889      0.926      0.795\n",
      "                  vase        128          2      0.868          1      0.995      0.895\n",
      "              scissors        128          1          1          0          0          0\n",
      "            teddy bear        128         21      0.833      0.905       0.97      0.717\n",
      "            toothbrush        128          5      0.863          1      0.995       0.76\n",
      "Speed: 1.1ms preprocess, 21.1ms inference, 0.0ms loss, 3.4ms postprocess per image\n",
      "Results saved to \u001b[1mruns\\detect\\train42\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model's performance on the validation set\n",
    "results = model.val()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1f6b880c-50b5-404c-9412-35c3a19ceee6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Found https://ultralytics.com/images/bus.jpg locally at bus.jpg\n",
      "image 1/1 C:\\Users\\Martin\\Documents\\GitHub\\yolov5_local_base\\bus.jpg: 640x480 4 persons, 1 bus, 1 cell phone, 154.8ms\n",
      "Speed: 8.1ms preprocess, 154.8ms inference, 5.0ms postprocess per image at shape (1, 3, 640, 480)\n"
     ]
    }
   ],
   "source": [
    "# Perform object detection on an image using the model\n",
    "results = model(\"https://ultralytics.com/images/bus.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "05a7d9f0-ca62-4d59-8b13-59222b1bde64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.1.32 🚀 Python-3.12.2 torch-2.2.1 CPU (12th Gen Intel Core(TM) i9-12900H)\n",
      "\n",
      "\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from 'runs\\detect\\train4\\weights\\best.pt' with input shape (1, 3, 640, 640) BCHW and output shape(s) (1, 84, 8400) (17.7 MB)\n",
      "\u001b[31m\u001b[1mrequirements:\u001b[0m Ultralytics requirement ['onnx>=1.12.0'] not found, attempting AutoUpdate...\n",
      "\u001b[31m\u001b[1mrequirements:\u001b[0m ❌ Command 'pip install --no-cache \"onnx>=1.12.0\" ' returned non-zero exit status 1.\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m export failure ❌ 20.2s: No module named 'onnx'\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'onnx'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Export the model to ONNX format\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m success \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexport\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43monnx\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\.conda\\envs\\ultralytics\\Lib\\site-packages\\ultralytics\\engine\\model.py:588\u001b[0m, in \u001b[0;36mModel.export\u001b[1;34m(self, **kwargs)\u001b[0m\n\u001b[0;32m    586\u001b[0m custom \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimgsz\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39margs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimgsz\u001b[39m\u001b[38;5;124m\"\u001b[39m], \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbatch\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m1\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mverbose\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28;01mFalse\u001b[39;00m}  \u001b[38;5;66;03m# method defaults\u001b[39;00m\n\u001b[0;32m    587\u001b[0m args \u001b[38;5;241m=\u001b[39m {\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moverrides, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcustom, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmode\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexport\u001b[39m\u001b[38;5;124m\"\u001b[39m}  \u001b[38;5;66;03m# highest priority args on the right\u001b[39;00m\n\u001b[1;32m--> 588\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mExporter\u001b[49m\u001b[43m(\u001b[49m\u001b[43moverrides\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_callbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\.conda\\envs\\ultralytics\\Lib\\site-packages\\torch\\utils\\_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    112\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[0;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    114\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[1;32m--> 115\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\.conda\\envs\\ultralytics\\Lib\\site-packages\\ultralytics\\engine\\exporter.py:287\u001b[0m, in \u001b[0;36mExporter.__call__\u001b[1;34m(self, model)\u001b[0m\n\u001b[0;32m    285\u001b[0m     f[\u001b[38;5;241m1\u001b[39m], _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexport_engine()\n\u001b[0;32m    286\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m onnx:  \u001b[38;5;66;03m# ONNX\u001b[39;00m\n\u001b[1;32m--> 287\u001b[0m     f[\u001b[38;5;241m2\u001b[39m], _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexport_onnx\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    288\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m xml:  \u001b[38;5;66;03m# OpenVINO\u001b[39;00m\n\u001b[0;32m    289\u001b[0m     f[\u001b[38;5;241m3\u001b[39m], _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexport_openvino()\n",
      "File \u001b[1;32m~\\.conda\\envs\\ultralytics\\Lib\\site-packages\\ultralytics\\engine\\exporter.py:138\u001b[0m, in \u001b[0;36mtry_export.<locals>.outer_func\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    136\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    137\u001b[0m     LOGGER\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mprefix\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m export failure ❌ \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdt\u001b[38;5;241m.\u001b[39mt\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.1f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124ms: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 138\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n",
      "File \u001b[1;32m~\\.conda\\envs\\ultralytics\\Lib\\site-packages\\ultralytics\\engine\\exporter.py:133\u001b[0m, in \u001b[0;36mtry_export.<locals>.outer_func\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    131\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    132\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m Profile() \u001b[38;5;28;01mas\u001b[39;00m dt:\n\u001b[1;32m--> 133\u001b[0m         f, model \u001b[38;5;241m=\u001b[39m \u001b[43minner_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    134\u001b[0m     LOGGER\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mprefix\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m export success ✅ \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdt\u001b[38;5;241m.\u001b[39mt\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.1f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124ms, saved as \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mf\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile_size(f)\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.1f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m MB)\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    135\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m f, model\n",
      "File \u001b[1;32m~\\.conda\\envs\\ultralytics\\Lib\\site-packages\\ultralytics\\engine\\exporter.py:359\u001b[0m, in \u001b[0;36mExporter.export_onnx\u001b[1;34m(self, prefix)\u001b[0m\n\u001b[0;32m    357\u001b[0m         check_requirements(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcmake\u001b[39m\u001b[38;5;124m\"\u001b[39m)  \u001b[38;5;66;03m# 'cmake' is needed to build onnxsim on aarch64\u001b[39;00m\n\u001b[0;32m    358\u001b[0m check_requirements(requirements)\n\u001b[1;32m--> 359\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01monnx\u001b[39;00m  \u001b[38;5;66;03m# noqa\u001b[39;00m\n\u001b[0;32m    361\u001b[0m opset_version \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mopset \u001b[38;5;129;01mor\u001b[39;00m get_latest_opset()\n\u001b[0;32m    362\u001b[0m LOGGER\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mprefix\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m starting export with onnx \u001b[39m\u001b[38;5;132;01m{\u001b[39;00monnx\u001b[38;5;241m.\u001b[39m__version__\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m opset \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mopset_version\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'onnx'"
     ]
    }
   ],
   "source": [
    "# Export the model to ONNX format\n",
    "# success = model.export(format=\"onnx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0fe312fc-78c6-4d8d-8155-bc4a7721971d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last updated: 2024-03-24T09:55:10.642182+01:00\n",
      "\n",
      "Python implementation: CPython\n",
      "Python version       : 3.12.2\n",
      "IPython version      : 8.22.2\n",
      "\n",
      "Compiler    : MSC v.1937 64 bit (AMD64)\n",
      "OS          : Windows\n",
      "Release     : 11\n",
      "Machine     : AMD64\n",
      "Processor   : Intel64 Family 6 Model 154 Stepping 3, GenuineIntel\n",
      "CPU cores   : 20\n",
      "Architecture: 64bit\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from watermark import watermark\n",
    "\n",
    "print(watermark())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f740d6d-9a5c-4924-86bc-73173039c786",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
